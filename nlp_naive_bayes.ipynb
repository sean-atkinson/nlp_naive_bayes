{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP, Naive Bayes, Cambridge Analytica, and Facebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cambridge Analytica logo on a phone in the foreground, with Facebook's logo in the background](https://imgur.com/mNXuoXU.jpg)\n",
    "*Getty Images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import CountVectorizer and TFIDFVectorizer from feature_extraction.text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "\n",
    "pd.options.display.max_rows = 200 #increasing maximum viewable rows and columns\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data science process:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the problem.\n",
    "\n",
    "Many organizations have a substantial interest in classifying users of their product into groups. \n",
    "\n",
    "With that in mind, let's place ourselves in the shoes of a Facebook engineer.\n",
    "\n",
    "Many of us are familiar with the whole Cambridge Analytica and how it tarnished Facebook's reputation since they were able to use Facebook's data in a bid to sway electoral outcomes.\n",
    "\n",
    "Cambridge Analytica, an organization staffed with lots of Ph.D. researchers, used the Big5 personality groupings (also called OCEAN) to group people into one of 32 different groups.\n",
    "- The five qualities measured by this personality assessment are:\n",
    "    - **O**penness\n",
    "    - **C**onscientiousness\n",
    "    - **E**xtroversion\n",
    "    - **A**greeableness\n",
    "    - **N**euroticism\n",
    "- Each person could be classified as \"Yes\" or \"No\" for each of the five qualities.\n",
    "- This makes for 32 different potential combinations of qualities. ($2^5 = 32$)\n",
    "- You can learn more on [Wikipedia](https://en.wikipedia.org/wiki/Big_Five_personality_traits) about the Big5 personality traits.\n",
    "- There's also [a short (3-4 pages) academic paper describing part of this approach](./celli-al_wcpr13.pdf) if you're *really* interested.\n",
    "\n",
    "Cambridge Analytica's methodology was, roughly, as follows:\n",
    "- Gather a large amount of data from Facebook.\n",
    "- Use this data to predict an individual's Big5 personality \"grouping.\"\n",
    "- Design political advertisements that would be particularly effective to that particular \"grouping.\" (For example, are certain advertisements particularly effective toward people with specific personality traits?)\n",
    "\n",
    "You want to know the **real-world problem**: \"Is what Cambridge Analytica attempted to do actually possible, or is it junk science?\"\n",
    "\n",
    "However, we'll solve the related **data science problem**: \"Are one's Facebook statuses predictive of whether or not one is agreeable?\"\n",
    "> Note: If Facebook statuses aren't predictive of one being agreeable (one of the OCEAN qualities), then Cambridge Analytica's approach won't work very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Obtain the data.\n",
    "\n",
    "Obviously, there are plenty of opportunities to discuss the ethics surrounding this particular issue... so let's do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./mypersonality_final.csv', encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/15/09 01:15 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/22/09 04:48 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/20/09 02:31 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65   3.0  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65   3.0  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65   3.0  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65   3.0  3.15  3.25   \n",
       "4                                        is home. <3  2.65   3.0  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU cAGR cCON cOPN               DATE  NETWORKSIZE  BETWEENNESS  \\\n",
       "0   4.4    n    y    n    n    y  06/19/09 03:21 PM        180.0      14861.6   \n",
       "1   4.4    n    y    n    n    y  07/02/09 08:41 AM        180.0      14861.6   \n",
       "2   4.4    n    y    n    n    y  06/15/09 01:15 PM        180.0      14861.6   \n",
       "3   4.4    n    y    n    n    y  06/22/09 04:48 AM        180.0      14861.6   \n",
       "4   4.4    n    y    n    n    y  07/20/09 02:31 AM        180.0      14861.6   \n",
       "\n",
       "   NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
       "0         93.29     0.03    15661.0        0.49           0.1  \n",
       "1         93.29     0.03    15661.0        0.49           0.1  \n",
       "2         93.29     0.03    15661.0        0.49           0.1  \n",
       "3         93.29     0.03    15661.0        0.49           0.1  \n",
       "4         93.29     0.03    15661.0        0.49           0.1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pop quiz: What's difference between anonymity and confidentiality? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confidentiality:\n",
    "Participation in an activity such as a research study is confidential. In these cases, participants provide personal information (e.g. name, email address, phone number), and can therefore be linked back to the results. The connection between the participants and the results are known, but the terms of the confidentiality agreement limit those who will know of this connection.\n",
    "\n",
    "Anonymity:\n",
    "In contrast, when participation is anonymous it is impossible to know whether or not an individual participated and, therefore, there is no way to determine the connection between individual participants and the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pop quiz: If that the \"unique identifier\" in the above data, the `#AUTHID`, is a randomly generated key so that it can never be connected back to the original poster. Have we guaranteed anonymity here? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, because the key cannot be connected back to the original poster, making it impossible to know who it was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of what you can do as aFacebook engineer to improve how data is used and shared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make it so the information can never be tracked back to a user by doing something similar to #AUTHID.\n",
    "2. Make users opt-in to sharing info about themselves, instead of having to opt-out, with advertisers and any other companies looking to use their info.\n",
    "3. Make it so that if users opt-out to sharing their info that they recieve the same level of service minus the targeted advertising."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Explore the data.\n",
    "\n",
    "- Note: For our $X$ variable, we'll only use the `STATUS` variable. For our $Y$ variable, we'll only use the `cAGR` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['n', 'y'], dtype=object)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cAGR'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    0.531209\n",
       "n    0.468791\n",
       "Name: cAGR, dtype: float64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cAGR'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#AUTHID</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>sEXT</th>\n",
       "      <th>sNEU</th>\n",
       "      <th>sAGR</th>\n",
       "      <th>sCON</th>\n",
       "      <th>sOPN</th>\n",
       "      <th>cEXT</th>\n",
       "      <th>cNEU</th>\n",
       "      <th>cAGR</th>\n",
       "      <th>cCON</th>\n",
       "      <th>cOPN</th>\n",
       "      <th>DATE</th>\n",
       "      <th>NETWORKSIZE</th>\n",
       "      <th>BETWEENNESS</th>\n",
       "      <th>NBETWEENNESS</th>\n",
       "      <th>DENSITY</th>\n",
       "      <th>BROKERAGE</th>\n",
       "      <th>NBROKERAGE</th>\n",
       "      <th>TRANSITIVITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes the sound of thunder.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/19/09 03:21 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is so sleepy it's not even funny that's she ca...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/02/09 08:41 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is sore and wants the knot of muscles at the b...</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/15/09 01:15 PM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>likes how the day sounds in this new song.</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>06/22/09 04:48 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b7b7764cfa1c523e4e93ab2a79a946c4</td>\n",
       "      <td>is home. &lt;3</td>\n",
       "      <td>2.65</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.4</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>0</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>07/20/09 02:31 AM</td>\n",
       "      <td>180.0</td>\n",
       "      <td>14861.6</td>\n",
       "      <td>93.29</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15661.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            #AUTHID  \\\n",
       "0  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "1  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "2  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "3  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "4  b7b7764cfa1c523e4e93ab2a79a946c4   \n",
       "\n",
       "                                              STATUS  sEXT  sNEU  sAGR  sCON  \\\n",
       "0                        likes the sound of thunder.  2.65   3.0  3.15  3.25   \n",
       "1  is so sleepy it's not even funny that's she ca...  2.65   3.0  3.15  3.25   \n",
       "2  is sore and wants the knot of muscles at the b...  2.65   3.0  3.15  3.25   \n",
       "3         likes how the day sounds in this new song.  2.65   3.0  3.15  3.25   \n",
       "4                                        is home. <3  2.65   3.0  3.15  3.25   \n",
       "\n",
       "   sOPN cEXT cNEU  cAGR cCON cOPN               DATE  NETWORKSIZE  \\\n",
       "0   4.4    n    y     0    n    y  06/19/09 03:21 PM        180.0   \n",
       "1   4.4    n    y     0    n    y  07/02/09 08:41 AM        180.0   \n",
       "2   4.4    n    y     0    n    y  06/15/09 01:15 PM        180.0   \n",
       "3   4.4    n    y     0    n    y  06/22/09 04:48 AM        180.0   \n",
       "4   4.4    n    y     0    n    y  07/20/09 02:31 AM        180.0   \n",
       "\n",
       "   BETWEENNESS  NBETWEENNESS  DENSITY  BROKERAGE  NBROKERAGE  TRANSITIVITY  \n",
       "0      14861.6         93.29     0.03    15661.0        0.49           0.1  \n",
       "1      14861.6         93.29     0.03    15661.0        0.49           0.1  \n",
       "2      14861.6         93.29     0.03    15661.0        0.49           0.1  \n",
       "3      14861.6         93.29     0.03    15661.0        0.49           0.1  \n",
       "4      14861.6         93.29     0.03    15661.0        0.49           0.1  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cAGR'] = data['cAGR'].map({'n': 0, 'y': 1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "#AUTHID         0\n",
       "STATUS          0\n",
       "sEXT            0\n",
       "sNEU            0\n",
       "sAGR            0\n",
       "sCON            0\n",
       "sOPN            0\n",
       "cEXT            0\n",
       "cNEU            0\n",
       "cAGR            0\n",
       "cCON            0\n",
       "cOPN            0\n",
       "DATE            0\n",
       "NETWORKSIZE     0\n",
       "BETWEENNESS     0\n",
       "NBETWEENNESS    0\n",
       "DENSITY         0\n",
       "BROKERAGE       0\n",
       "NBROKERAGE      0\n",
       "TRANSITIVITY    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataa into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Instantiate CountVectorizer.\n",
    "cv = CountVectorizer()\n",
    "\n",
    "# Fit CountVectorizer to training data.\n",
    "cv.fit(X_train)\n",
    "\n",
    "# Transform training and testing data based on the fit CountVectorizer.\n",
    "X_train_cv = cv.transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with our words.\n",
    "words = pd.DataFrame(X_train_cv.todense(), columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "propname    981\n",
       "day         392\n",
       "like        382\n",
       "get         366\n",
       "one         349\n",
       "go          327\n",
       "time        325\n",
       "going       318\n",
       "today       310\n",
       "back        295\n",
       "new         291\n",
       "work        280\n",
       "good        278\n",
       "got         233\n",
       "night       224\n",
       "know        211\n",
       "love        208\n",
       "tomorrow    206\n",
       "people      199\n",
       "see         198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the most frequently used words.\n",
    "words.sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the lengths of the words.\n",
    "lengths_of_words = [len(each) for each in words.columns]\n",
    "plt.hist(lengths_of_words)\n",
    "plt.title('Histogram of Word Lengths');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the lengths of the posts.\n",
    "lengths_of_posts = [len(each) for each in X]\n",
    "plt.hist(lengths_of_posts)\n",
    "plt.title('Histogram of Post Lengths');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer and TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In CountVectorizer, we only count the number of times a word appears in documents, which results in biasing in favour of most frequent words. This approach ends up in ignoring rare words, which could help process our data more efficiently.\n",
    "\n",
    "In TfidfVectorizer we consider overall document weightage of a word. It penalizes words that are used with greater frequencey between documents. A TF-IDF score tells us which words are most differentiating between documents. Words that occur often in one document but don't occur in many documents contain a great deal of predictive power. Consequently, it gives greater weigh to words that are rarer relative to all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopwords are commonly used words that provide little to no informational value. By removing them, it's easier to focus on the words that truly differentiate one document from the next.\n",
    "\n",
    "If we think these words don't help explain our  𝑌  variable, we might remove them. \n",
    "\n",
    "(For example, in sentiment analysis, we might not think that people who use \"the\" more or less frequently are happier or angrier.)\n",
    "\n",
    "If we think these words do help explain our  𝑌  variable, we might keep them. \n",
    "\n",
    "(For example, if we're classifying the era of a poem, the frequency of the word \"the\" may be helpful information!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model the data.\n",
    "\n",
    "We are going to fit two types of models: a logistic regression and [a Naive Bayes classifier](https://scikit-learn.org/stable/modules/naive_bayes.html).\n",
    "\n",
    "**Reminder:** We will only use the feature `STATUS` to model `cAGR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll attempt to fit our models on sixteen sets of features:\n",
    "\n",
    "1. CountVectorizer with 100 features, with English stopwords removed and with an `ngram_range` that includes 1 and 2.\n",
    "2. CountVectorizer with 100 features, with English stopwords removed and with the default `ngram_range`.\n",
    "3. CountVectorizer with 100 features, with English stopwords kept in and with an `ngram_range` that includes 1 and 2.\n",
    "4. CountVectorizer with 100 features, with English stopwords kept in and with the default `ngram_range`.\n",
    "5. CountVectorizer with 500 features, with English stopwords removed and with an `ngram_range` that includes 1 and 2.\n",
    "6. CountVectorizer with 500 features, with English stopwords removed and with the default `ngram_range`.\n",
    "7. CountVectorizer with 500 features, with English stopwords kept in and with an `ngram_range` that includes 1 and 2.\n",
    "8. CountVectorizer with 500 features, with English stopwords kept in and with the default `ngram_range`.\n",
    "9. TFIDFVectorizer with 100 features, with English stopwords removed and with an `ngram_range` that includes 1 and 2.\n",
    "10. TFIDFVectorizer with 100 features, with English stopwords removed and with the default `ngram_range`.\n",
    "11. TFIDFVectorizer with 100 features, with English stopwords kept in and with an `ngram_range` that includes 1 and 2.\n",
    "12. TFIDFVectorizer with 100 features, with English stopwords kept in and with the default `ngram_range`.\n",
    "13. TFIDFVectorizer with 500 features, with English stopwords removed and with an `ngram_range` that includes 1 and 2.\n",
    "14. TFIDFVectorizer with 500 features, with English stopwords removed and with the default `ngram_range`.\n",
    "15. TFIDFVectorizer with 500 features, with English stopwords kept in and with an `ngram_range` that includes 1 and 2.\n",
    "16. TFIDFVectorizer with 500 features, with English stopwords kept in and with the default `ngram_range`.\n",
    "\n",
    "### Rather than manually instantiating 16 different vectorizers, we'll use pipelines to make things easier on ourselves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch score with CountVectorized features on training set is 0.6195.\n",
      "\n",
      "GridSearch score with CountVectorized features on testing set is 0.5434.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate pipeline.\n",
    "pipe_cv = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(solver = 'lbfgs'))\n",
    "])\n",
    "\n",
    "# Define grid of parameters to GridSearch over.\n",
    "params_grid = {\n",
    "    'cv__max_features': [100, 500],\n",
    "    'cv__stop_words': ['english', None],\n",
    "    'cv__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# GridSearch over pipeline with given grid of parameters.\n",
    "gs_cv = GridSearchCV(pipe_cv, params_grid, cv=5)\n",
    "\n",
    "# Fit model.\n",
    "gs_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f'GridSearch score with CountVectorized features on training set is {round(gs_cv.score(X_train, y_train), 4)}.')\n",
    "print()\n",
    "print(f'GridSearch score with CountVectorized features on testing set is {round(gs_cv.score(X_test, y_test), 4)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch score with TFIDFVectorized features on training set is 0.6189.\n",
      "\n",
      "GridSearch score with TFIDFVectorized features on testing set is 0.5426.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate pipeline.\n",
    "pipe_tf = Pipeline([\n",
    "    ('tf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Define grid of parameters to GridSearch over.\n",
    "params_grid = {\n",
    "    'tf__max_features': [100, 500],\n",
    "    'tf__stop_words': ['english', None],\n",
    "    'tf__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# GridSearch over pipeline with given grid of parameters.\n",
    "gs_tf = GridSearchCV(pipe_tf, params_grid, cv=5)\n",
    "\n",
    "# Fit model.\n",
    "gs_tf.fit(X_train, y_train)\n",
    "\n",
    "print(f'GridSearch score with TFIDFVectorized features on training set is {round(gs_tf.score(X_train, y_train),4)}.')\n",
    "print()\n",
    "print(f'GridSearch score with TFIDFVectorized features on testing set is {round(gs_tf.score(X_test, y_test),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages to fitting a logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic regression models are fast to fit.\n",
    "- Logistic regression models allow for us to interpret coefficients and the association between individual independent variables and the dependent variable. (Though it takes some computation to interpret them.)\n",
    "- Logistic regression models are more widely used and thus better understood than other techniques.\n",
    "- Logistic regression models often perform on par with or better than more \"complex\"/unfamiliar machine learning methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's fit a logistic regression model and compare it to the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.531128\n",
       "0    0.468872\n",
       "Name: cAGR, dtype: float64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline performance.\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab best estimator from gs_cv.\n",
    "lr_model = gs_cv.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model.\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score for our logistic regression model is: 0.9107.\n",
      "Testing accuracy score for our logistic regression model is: 0.5845.\n"
     ]
    }
   ],
   "source": [
    "print(f'Training accuracy score for our logistic regression model is: {round(lr_model.score(X_train, y_train),4)}.')\n",
    "print(f'Testing accuracy score for our logistic regression model is: {round(lr_model.score(X_test, y_test),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes \n",
    "\n",
    "A classification technique that relies on probability to classify observations:\n",
    "- It's based on a probability rule called **Bayes' Theorem**... thus, \"**Bayes**.\"\n",
    "- It makes an assumption that isn't often met, so it's \"**naive**.\"\n",
    "\n",
    "Despite being a model that relies on a naive assumption, it often performs pretty well! \n",
    "\n",
    "(This is kind of like linear regression... we aren't always guaranteed homoscedastic errors in linear regression, but the model might still do a good job regardless.)\n",
    "\n",
    "- [Read more here if you're interested.](https://www.cs.unb.ca/~hzhang/publications/FLAIRS04ZhangH.pdf)\n",
    "\n",
    "#### Bayes' Theorem\n",
    "If you've seen Bayes' Theorem, it relates the probability of $P(A|B)$ to $P(B|A)$. \n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Bayes' Theorem: } P(A|B) &=& \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "- Let $A$ be that someone is \"agreeable,\" like the OCEAN category.\n",
    "- Let $B$ represent the words used in their Facebook post.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Bayes' Theorem: } P(A|B) &=& \\frac{P(B|A)P(A)}{P(B)} \\\\\n",
    "\\Rightarrow P(\\text{person is agreeable}|\\text{words in Facebook post}) &=& \\frac{P(\\text{words in Facebook post}|\\text{person is agreeable})P(\\text{person is agreeable})}{P(\\text{words in Facebook post})}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "We want to calculate the probability that someone is agreeable **given** the words that they used in their Facebook post! \n",
    "\n",
    "(Rather than calculating this probability by hand, this is done under the hood and we can just see the results by checking `.predict_proba()`.) However, this is exactly what our model is doing. We can (a.k.a. the model can) calculate the pieces on the right-hand side of the equation to give us a probability estimate of how likely someone is to be agreeable given their Facebook post.\n",
    "\n",
    "#### Naive Assumption\n",
    "\n",
    "If our goal is to estimate $P(\\text{person is agreeable}|\\text{words in Facebook post})$, that can be quite tricky.\n",
    "\n",
    "To simplify matters, we make an assumption: **we assume that all of our features are independent of one another.**\n",
    "\n",
    "In some contexts, this assumption might be realistic!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why would this assumption not be realistic with NLP data?\n",
    "\n",
    "Because the meaning of a sentence is dependent on the words within it. \n",
    "\n",
    "Text has little to no meaning without taking into the consideration the words that come before and after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite this assumption not being realistic with NLP data, we still use Naive Bayes pretty frequently.\n",
    "- It's a very fast modeling algorithm. (which is great especially when we have lots of features and/or lots of data!)\n",
    "- It is often an excellent classifier, outperforming more complicated models.\n",
    "\n",
    "There are three common types of Naive Bayes models: Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes.\n",
    "- How do we pick which of the three models to use? It depends on our $X$ variable.\n",
    "    - Bernoulli Naive Bayes is appropriate when our features are all 0/1 variables.\n",
    "        - [Bernoulli NB Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html#sklearn.naive_bayes.BernoulliNB)\n",
    "    - Multinomial Naive Bayes is appropriate when our features are variables that take on only positive integer counts.\n",
    "        - [Multinomial NB Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
    "    - Gaussian Naive Bayes is appropriate when our features are Normally distributed variables. (Realistically, though, we kind of use Gaussian whenever neither Bernoulli nor Multinomial works.)\n",
    "        - [Gaussian NB Documentation](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we're going CountVectorize our features, we'd use  Multinomial Naive Bayes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the the variables are integer counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score for our Multinomial Naive Bayes model is: 0.8674.\n",
      "\n",
      "Testing accuracy score for our Multinomial Naive Bayes model is: 0.6123.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate Multinomial Naive Bayes model.\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fit model.\n",
    "mnb.fit(X_train_cv, y_train)\n",
    "\n",
    "# Evaluate predictions.\n",
    "print(f'Training accuracy score for our Multinomial Naive Bayes model is: {round(mnb.score(X_train_cv, y_train),4)}.')\n",
    "print()\n",
    "print(f'Testing accuracy score for our Multinomial Naive Bayes model is: {round(mnb.score(X_test_cv, y_test),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. If we TFIDFVectorize oour features, we'd use  Gaussian Naive Bayes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because X is a float and also not a count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy score for our Gaussian Naive Bayes model is: 0.8653.\n",
      "\n",
      "Testing accuracy score for our Gaussian Naive Bayes model is: 0.5409.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate TFIDFVectorizer.\n",
    "tf = TfidfVectorizer()\n",
    "\n",
    "# Fit vectorizer.\n",
    "tf.fit(X_train, y_train)\n",
    "\n",
    "# Transform training and testing sets.\n",
    "X_train_tf = tf.transform(X_train).todense()\n",
    "X_test_tf = tf.transform(X_test).todense()\n",
    "\n",
    "# Instantiate Gaussian Naive Bayes model.\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit model.\n",
    "gnb.fit(X_train_tf, y_train)\n",
    "\n",
    "# Evaluate predictions,\n",
    "print(f'Training accuracy score for our Gaussian Naive Bayes model is: {round(gnb.score(X_train_tf, y_train),4)}.')\n",
    "print()\n",
    "print(f'Testing accuracy score for our Gaussian Naive Bayes model is: {round(gnb.score(X_test_tf, y_test),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Which model the performanced the best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a baseline model would be about 0.5311.\n",
      "\n",
      "Training accuracy score for our logistic regression model is: 0.9107.\n",
      "\n",
      "Testing accuracy score for our logistic regression model is: 0.5845.\n",
      "\n",
      "Training accuracy score for our Multinomial Naive Bayes model is: 0.8674.\n",
      "\n",
      "Testing accuracy score for our Multinomial Naive Bayes model is: 0.6123.\n",
      "\n",
      "Training accuracy score for our Gaussian Naive Bayes model is: 0.8653.\n",
      "\n",
      "Testing accuracy score for our Gaussian Naive Bayes model is: 0.5409.\n"
     ]
    }
   ],
   "source": [
    "print(f'The accuracy of a baseline model would be about {round(y_train.value_counts(normalize=True)[1],4)}.')\n",
    "print()\n",
    "print(f'Training accuracy score for our logistic regression model is: {round(lr_model.score(X_train, y_train),4)}.')\n",
    "print()\n",
    "print(f'Testing accuracy score for our logistic regression model is: {round(lr_model.score(X_test, y_test),4)}.')\n",
    "print()\n",
    "print(f'Training accuracy score for our Multinomial Naive Bayes model is: {round(mnb.score(X_train_cv, y_train),4)}.')\n",
    "print()\n",
    "print(f'Testing accuracy score for our Multinomial Naive Bayes model is: {round(mnb.score(X_test_cv, y_test),4)}.')\n",
    "print()\n",
    "print(f'Training accuracy score for our Gaussian Naive Bayes model is: {round(gnb.score(X_train_tf, y_train),4)}.')\n",
    "print()\n",
    "print(f'Testing accuracy score for our Gaussian Naive Bayes model is: {round(gnb.score(X_test_tf, y_test),4)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our MNB model perfromed the best with 61%, which is 8 points above baseline or a 14.6% increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circling back to Cambridge Analytica, how effective was their approach at using Facebook data to model agreeableness?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not very!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
